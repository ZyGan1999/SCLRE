<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" class="gr__shape2prog_csail_mit_edu"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

              <meta name="viewport" content="width=device-width, initial-scale=1">    <link rel="shortcut icon" href="http://shape2prog.csail.mit.edu/images/favicon.ico">
        <meta name="description" content="Superclass Learning with Representation Enhancement">
        <meta name="keywords" content="Superclass Learning with Representation Enhancement">

        <title>Superclass Learning with Representation Enhancement</title>
        <link rel="stylesheet" href="asset/font.css">
        <link rel="stylesheet" href="asset/main.css">

    </head>

    <body data-gr-c-s-loaded="true">

        <div class="outercontainer">
            <div class="container">

                <div class="content project_title">
                    <h1>Superclass Learning with Representation Enhancement</h1>
                </div>

                <div class="content project_headline">
                    <center><h2>
                      <font size="3">Zeyu Gan, Suyun Zhao, Jinlong Kang, Liyuan Shang, Hong Chen, Cuiping Li</font>&nbsp;&nbsp;
                   
                </div>


                


                <div class="content">
                    <div class="text">
                        <h1>Abstract</h1>
                        <p><font size=3>In many real scenarios, data are often divided into a handful of artificial super 
                            categories in terms of expert knowledge rather than the representations of images. Concretely, 
                            a superclass may contain massive and various raw categories, such as refuse sorting. Due to the 
                            lack of common semantic features, the existing classification techniques are intractable to recognize 
                            superclass without raw class labels, thus they suffer severe performance damage or require huge annotation costs. 
                            To narrow this gap, this paper proposes a superclass learning framework, called SuperClass Learning with Representation 
                            Enhancement(SCLRE), to recognize super categories by leveraging enhanced representation. Specifically, by exploiting 
                            the self-attention technique across the batch, SCLRE collapses the boundaries of those raw categories and enhances the 
                            representation of each superclass. On the enhanced representation space, a superclass-aware decision boundary is then reconstructed. 
                            Theoretically, we prove that by leveraging attention techniques the generalization error of SCLRE can be bounded under superclass scenarios. 
                            Experimentally, extensive results demonstrate that SCLRE outperforms the baseline and other contrastive-based methods on CIFAR-100 datasets 
                            and four high-resolution datasets.</font></p>
                    </div>
                </div>

                <div class="content">
                    <div class="text">
                        <h1>1. Introduction & Motivation</h1>
                        <div class="content project_headline">
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/intro.png" alt="Intro" style="margin:auto;max-width:80%">
                        </div>
                        <div class="text">
                            <p><font size=3>Figure 1: An illustration of superclass problem.</font></p>
                        </div>
                        <div class="text">
                        In real-world applications, the criteria for image classification are often determined by human cognition rather than the 
                        features of the images themselves. In some scenarios, due to overly coarse-grained criteria, a category of images may contain 
                        various subclasses, resulting in a lack of common semantic features even among images belonging to the same class. For example, 
                        in the context of waste classification, images of recyclable waste include a wide range of items, from beverage cans to books, 
                        with no apparent commonality. This article defines this phenomenon as the "Superclass Learning" problem.
                        </div>
                        <div class="content">
                        
                        <h3>Characteristics of Superclass Learning</h3>
                        <p><ul class="download">
							<font size=3>
                            <li>Subclasses within a superclass are usually scattered and share few common features.</li>
							<li>Instances from different superclasses may have common features, leading to potential confusion between classes.</li>
                            </font>
                        </ul></p>

                        <h3>Challenges of Superclass Learning</h3>
                        <p><ul class="download">
							<font size=3>
                            <li><b>Breaking the original basic class decision boundaries</b>(Fig 1.b): It is necessary to divide the domain into smaller, more meaningful domains that better represent the actual problem (e.g., splitting the apple domain into fruit and toy domains).</li>
							<li><b>Reconstructing decision boundaries at the superclass level</b>(Fig 1.c): The goal is to merge relevant class domains into a new superclass domain that accurately represents the intended classification (e.g., combining fruit apples, eggs, and bones into a food waste superclass domain).</li>
                            </font>
                        </ul></p>
                        </div>

                        <div class="content">
                            <h3>Contribution of this paper</h3>
                        <p><ul class="download">
							<font size=3>
                            <li>We propose the under-study but realistic problem, superclass learning.</li>
							<li>We propose a novel representation enhancement method (SCLRE) to address superclass learning.</li>
                            <li> We perform extensive experiments to demonstrate that SCLRE outperforms other SOTA classification techniques.</li>
                            </font>
                        </ul></p>
                        </div>
                    </div>
                    </div>
                </div>
                <div class="content">
                    <div class="text">
                        <h1>2. Framework of SCLRE</h1>
                    </div>

                    <div class="content project_headline">
					
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/model.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        <div class="text">
                            <p><font size=3>Figure 2: Overview of the process of SCLRE.</font></p>
                        </div>
                        <div class="text">
                            SCLRE process the images in the following steps. The images first generate their representations 
                            through a convolutional neural network, then mix with each other in a trainable cross-instance 
                            attention module for enhancement. After enhancement, the representations are then adjusted according 
                            to their superclass labels and the target anchors.
                        </div>

                        <div class="content">
                            <h3>Enhancement</h3>
                        <p><ul class="download">
							<font size=3>
                            <li>We calculate the attention weights by putting the batch images into a cross-instance attention module.</li>
							<li>We use the attention weights to mix the representations with each other.</li>
                            </font>
                        </ul></p>
                        </div>

                        <div class="content">
                            <h3>Adjustment</h3>
                        <p><ul class="download">
							<font size=3>
                            <li>We adjust the enhanced representations under the guidance of a supervised contrastive loss.</li>
							<li>We also preset target anchors for each superclass to help the adjustment process.</li>
                            </font>
                        </ul></p>
                        </div>

                        <div class="text">
                            More details about the enhancement and adjustment process are shown in our paper (Sec.3).
                        </div>
                        
                    </div>
					
                </div>
				<div class="content">
                    <div class="text">
                        <h1>3. Experiment Result</h1>

						<h2> 3.1 Accuracy </h2>
						
						<div class="content project_headline">
						<div class="text">
                            <p><font size=3>Table 1&2: Accuracy on Multiple Datasets.</font></p>
                        </div>
						<div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/accuracy.png" alt="result" style="margin:auto;max-width:90%">
                        </div>
                        <div class="text">
                            We reorganize the raw classes of these datasets and make them superclass problems. The classification 
                            results show that SCLRE outperforms the SOTA representation learning framework.
                        </div>

                        <h2> 3.2 Visualization </h2>
					
                        <div class="img" style="text-align:center">
                            <img class="img_responsive" src="asset/visualization.png" alt="result" style="margin:auto;max-width:90%">
                            <div class="text">
                                <p><font size=3>Figure 3: Visualization of Representation Space.</font></p>
                            </div>
                        </div>

                        <div class="text">
                            We use t-SNE to visualize the representation space of each compared mathod. The result shows that SCLRE can 
                            effectively scratch superclass-aware representations and make the boundaries of each superclass more clear.
                        </div>
                        
                        </div class="text">
                            More experiment results like ablation, sensetivity and robustness are shown in our paper.
                        </div>
                    </div>
                </div>


                <div class="content">
                    <div class="text">
                    <h1>4. Analysis of Generalization</h1>
                    <div class="text">
                    According to the theory of contrastive learning, we analyze the generalization upper bound of SCLRE.The details of the proof 
                    are shown in the paper and appendix. To draw a conclusion, The generalization error can be bounded by the similarity of attention 
                    vectors from the same superclass in the form of the following equation:
                    </div>
                    <div class="img" style="text-align:center">
                        <img class="img_responsive" src="asset/error.png" alt="result" style="margin:auto;max-width:90%">
                    </div>
                    <div class="text">
                        During the training process, for the samples of the same superclass under the same task, the SCLRE training process 
                        can help to discover samples that are more important to the construction of the superclass structure, and they should 
                        also be similar to the samples in the same superclass. Therefore, the sample pairs in O2 can naturally have high 
                        similarity attention vectors, thereby reducing the upper bound of the generalization error, which is consistent with 
                        the phenomenon we observed in the experiment.
                    </div>
                    </div>
                </div>
               
                <div class="content">
                    <div class="text">
                        <h1>5. BibTex  </h1>
						
						<div class="content">
                            @InProceedings{Gan_2023_CVPR,
    author    = {Gan, Zeyu and Zhao, Suyun and Kang, Jinlong and Shang, Liyuan and Chen, Hong and Li, Cuiping},
    title     = {Superclass Learning With Representation Enhancement},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {24060-24069}
}
                        </div>
                    </div>
                </div>

</body></html>


